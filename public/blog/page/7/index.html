
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Mere Code</title>
  <meta name="author" content="Jonathan Lange">

  
  <meta name="description" content="Since the late nineties, I&#8217;ve had my IRC clients configured to complete nicks with a colon. For example:&lt;jml&gt; dash: there's an otherwise &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://code.mumak.net/blog/page/7/index.html">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Mere Code" type="application/atom+xml">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <div id="logo">
  	<div id="logoLeft">(</div>
  	<div id="logoText">jml</div>
  	<div id="logoRight">)</div>
  	<div class="clear"></div>
  </div>
  <h1><a href="/">Mere Code</a></h1>
  
    <h2>Diverse Topics of General Interest to the Practicing Programmer</h2>
  
  <div class="clear"></div>
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:code.mumak.net" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About this blog</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/2010/09/get-xchat-gnome-completing-with-colon.html">Get Xchat-Gnome completing with colon</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-09-27T00:00:00+01:00" pubdate data-updated="true">2010-09-27 Monday</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
Since the late nineties, I&#8217;ve had my IRC clients configured to complete nicks with a colon. For example:<br /><br /><pre>&lt;jml&gt; dash: there's an otherwise normal guy at work who uses tcl as his scripting language of choice</pre><br />But during some Ubuntu upgrade at some point in the last couple of years, Xchat-Gnome changed my settings without telling me. Now it completes nicks like this:<br /><br /><pre>&lt;jml&gt; itamar, a cunning, enviable balance between argument and unsupported assertion</pre><br />Which is so clearly inferior to a colon-based nick-completion that I do not have to list the reasons. There are many.<br /><br />In any case, today I figured out how to change it:<br /><br /><pre>/set completion_suffix :<br /></pre><br />That&#8217;s it. Xchat will take care of saving the configuration for you. I&#8217;m so happy.<br /><br /><b>Update:</b>&nbsp;Actually, no, Xchat does <i>not</i> take care of saving the configuration for you.<br /><br />You must open <code>~/.xchat2/xchat.conf</code>, find the line that says <code>completion_suffix = ,</code> and change it to say <code>completion_suffix = :</code> and then, crucially, <i>save</i> your changes to that file. You&#8217;ll probably have to restart Xchat as well.</div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>Gary van der Merwe<span class='comment-date'> on 2010-09-28 21:01</span></div>
<div class='content'>
Nice - You made me happy too!</div>
</div>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/2010/09/maverick-notes.html">Maverick notes</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-09-16T00:00:00+01:00" pubdate data-updated="true">2010-09-16 Thursday</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
I recently upgraded to Maverick beta. Here are my thoughts and observations:<br /><br /><ul><li>Despite the huge number of PPAs and unofficial debs I had on my system, the upgrade itself was very smooth</li><li>Everything looks much crisper, probably due to the <a href="http://design.canonical.com/2010/08/an-update-to-the-ubuntu-light-themes/">two</a> <a href="http://design.canonical.com/2010/08/second-update-to-the-ubuntu-light-themes/">updates</a> to the Light themes</li><li>Python 2.5 was removed. I work on software that still supports Python 2.4, so that&#8217;s a pain</li><li>The keyboard indicator is nicer (I can read it), but it says &#8220;USA&#8221; when I want it to say &#8220;Dvorak&#8221;</li><li>The booting process is still flashes between screen resolutions, switches to black then back again</li><li>I still have to rmmod iwlagn; modprobe iwlagn sometimes</li><li>&#8220;Print to file&#8221; from Chrome produced a single blank page of PDF</li><li>I don&#8217;t know how I feel about the Me &amp; Message menus</li></ul><div>I guess lots of these are bugs. They are, after all, easier to notice.</div></div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>jml<span class='comment-date'> on 2010-09-17 09:51</span></div>
<div class='content'>
Ooh. Thanks for the tip.</div>
</div>
<div class='comment'>
<div class='author'>spiv<span class='comment-date'> on 2010-09-17 06:39</span></div>
<div class='content'>
<a href="https://edge.launchpad.net/~fkrull/+archive/deadsnakes" rel="nofollow">https://edge.launchpad.net/~fkrull/+archive/deadsnakes</a> looks useful: a PPA with python2.4 and python2.5 for Maverick (and Lucid).  That doesn&#39;t help with all the python libraries you might depend on, but it&#39;s something.<br /><br />I guess the comprehensive answer is &quot;run a virtual machine with Hardy&quot;.</div>
</div>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/2010/09/what-we-do.html">What we do</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-09-15T00:00:00+01:00" pubdate data-updated="true">2010-09-15 Wednesday</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
I&#8217;ve just come back from a couple of weeks off.  Unusually, I didn&#8217;t spend much time programming or thinking about work, instead I was just enjoying life and getting enough sleep. How fortunate then to return and find out that we&#8217;re being encouraged to think about what we do at Canonical.<br /><br />I work on Launchpad, readers will know this by now.  Launchpad is a very, very big web application that has the fundamental purpose of accelerating open source collaboration, particularly within the Ubuntu sphere.<br /><br />This rather happily meshes with a deep passion of mine, which is to make programming better.<br /><br />The main reason I am personally involved with open source, and the reason I sometimes make sacrifices in order to support it, is because I believe that sharing and talking about code is the only way to get better at programming. That&#8217;s why I care so much about <a href="http://mumak.net/stuff/your-code-sucks.html">code review</a>.  When I look critically at a proprietary product like Gmail or OmniFocus, I can learn much about user interface and product design, but I can&#8217;t learn anything about programming. With open source, I can learn from the world, and perhaps make my own small contribution back.<br /><br />But so often with open source software, the barrier to entry is high for silly reasons.  It&#8217;s often hard to find the bug tracker, you can trawl around a website for minutes losing valuable interest looking for an svn checkout URL, sometimes it&#8217;s hard to figure out the name of the project. Then, once you&#8217;ve got the project, you have to figure out how to build it and run it. Once your patch is done you have to figure out where to submit it.<br /><br />All of this can be tedious even when you are already heavily involved in a project. The first time, though, it&#8217;s often impossibly difficult.<br /><br />Some of my colleagues would perhaps tell you how angry this makes me.  Human beings are meant for engaging work that requires intelligence, not arbitrary drudgery that can be solved by a mere machine. For programmers, it&#8217;s doubly worse, since our trade is entirely about automating the automatable.<br /><br />To really get to the heart of the problem though, serious investment is needed in collaboration tools.  And that is exactly what Canonical is doing to this day with Launchpad and Bazaar.<br /><br />We are working to make much of the above simpler: predictable URLs for Git, Subversion, CVS and Bazaar repositories using our imports and &#8216;bzr get lp:project&#8217;, one bug tracker that can forward bugs to whatever it is that a project uses, a consistent user interface across projects.<br /><br />To take one recent example, <a href="http://www.markshuttleworth.com/archives/507">Launchpad and Bazaar combine to make it a doddle to always be running trunk on your Ubuntu desktop</a>. Imagine that! End users running fresh trunk every day without having to build it.<br /><br />Or you might consider <a href="https://launchpad.net/lernid">Lernid</a>. It&#8217;s a small project that helps people learn and teach over IRC, started by <a href="http://www.jonobacon.org/">Jono Bacon</a>. Jono speaks only roughly dialect of English, but Launchpad connected his project with a bunch of wonderful people who translated it into their own languages. My rough count&nbsp;puts it at <a href="https://translations.edge.launchpad.net/lernid/trunk">twelve different languages</a>. The same thing has happened with many, many projects on Launchpad.<br /><br />There&#8217;s still much to be done, but we have already made an impact. Thousands of people have used Launchpad to share code, hundreds of thousands have reported bugs, many projects exist that wouldn&#8217;t have before. And all of this flows into an open, free, Linux desktop that I am proud to say I have contributed to.</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/2010/09/leaps-and-bounds.html">Leaps and bounds</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-09-13T00:00:00+01:00" pubdate data-updated="true">2010-09-13 Monday</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
If your development process has something like &#8220;before you run $CUSTOM_SCRIPT_1, run $CUSTOM_SCRIPT_2 to make sure everything is OK&#8221;, then you are doing it wrong. Couple leaping with looking.</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/2010/09/back.html">Back</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-09-13T00:00:00+01:00" pubdate data-updated="true">2010-09-13 Monday</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
After a wonderful two week break, I&#8217;m now back in high-backed chair of Launchpad strategy. Can&#8217;t wait to see what&#8217;s been happening.</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/2010/09/why-you-should-write-your-tests-first.html">Why you should write your tests first</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-09-07T00:00:00+01:00" pubdate data-updated="true">2010-09-07 Tuesday</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
We&#8217;re all agreed that any Python code that&#8217;s even a little serious needs unit tests, right? However, sometimes we end up writing our tests after we&#8217;ve written our code rather than doing test-driven development, what <a href="http://curtis.hovey.name/">Curtis</a> calls &#8220;code and cover&#8221;. That&#8217;s bad. Here&#8217;s why.<br /><ol><li>It&#8217;s dull. Really dull.</li><li>You find bugs, but it&#8217;s somehow more frustrating. Perhaps because you thought your code was correct already.</li><li>The code is probably not written for testability, which means you have to mix refactoring up with verifying behaviour. Messy &amp; perilous.</li><li>Alternatively, you write tests with a <a href="http://martinfowler.com/articles/mocksArentStubs.html">lot of mocks</a>. Not bad in itself, but risky.</li><li>It&#8217;s much harder to get full coverage.</li><li>You write tests for things that you don&#8217;t care about, just to exercise a particular code path. This makes the tests more <a href="http://xunitpatterns.com/Fragile%20Test.html">fragile</a>.</li><li>You never really know when you are finished.</li></ol><div>Are you a TDDer or a code-and-cover person? Why do you prefer it that way?</div></div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>Kevin H<span class='comment-date'> on 2010-09-22 23:46</span></div>
<div class='content'>
I tend to sketch out a minimal &quot;spike solution&quot;, then write some tests for it, and then use TDD to add functionality and make sure corner cases get handled.</div>
</div>
<div class='comment'>
<div class='author'>jml<span class='comment-date'> on 2010-09-14 14:29</span></div>
<div class='content'>
Thanks for the comments everyone.<br /><br />Julian, if by prototype you mean &quot;proof of concept&quot;, then I also often don&#39;t do that TDD. What tends to happen with those is that the prototype <i>becomes</i> the tests. (After all, how did I know it worked?).<br /><br /><br />Glyph, I would love to write up a more detailed version of this post. It&#39;s unlikely I&#39;ll have the time.<br /><br />A thing that can help with untested mocks &amp; stubs is &quot;interface verification tests&quot;: one set of tests that runs against the real thing and against a more easily testable thing.</div>
</div>
<div class='comment'>
<div class='author'>jkakar<span class='comment-date'> on 2010-09-09 03:53</span></div>
<div class='content'>
Whether you do TDD or code-and-cover it&#39;s very important to make sure your test fails when the code you think it is testing is broken (or gone).  Doing TDD ensures this fail-when-broken check happens for each test.  This validation can be performed with code-and-cover, but it is much more tedious.<br /><br />I prefer TDD but use code-and-cover when I really don&#39;t understand what I need.  In that case, the code-and-cover I do is to (1) spike until I know what I want and then (2) comment out my code and TDD until it&#39;s all uncommented and covered properly.</div>
</div>
<div class='comment'>
<div class='author'>glyph<span class='comment-date'> on 2010-09-08 21:19</span></div>
<div class='content'>
&#8230; and another thing.<br /><br />There is one case where not writing tests first is actually a better idea, I think.<br /><br />If you have some code with a lot of dependencies and no test support for those dependencies (where &quot;test support&quot; means mocks, fakes, stubs, in-memory implementations, or what-have-you), sometimes TDD means that you have to start off by writing a largeish pile of unmaintainable one-off junk just to stub out enough to get a simple test running.<br /><br />I go back and forth on this, but I am coming to be of the opinion that having big piles of unmaintainable test stubs <em>can</em> be a worse problem than having poor coverage.  The stubs and functionality and interfaces can diverge from the &quot;real&quot; implementations, and inevitably you end up having to maintain a couple dozen fake implementations of the not-really-test-supported interfaces, each of which has its own quirks.  This can lead to lots of false failures, which leads to decreased trust in the test suite, which is of course bad.<br /><br />If you&#39;re adding functionality to a system, you can usually manage this problem by implementing the new functionality itself in a corner, with only the dependencies that it really needs, and keep the test maintenance burden sane.  Rather than try to make sure that the integration code is properly TDD, the goal is then to just keep the integration code (which glues your shiny new TDD-developed module into the system) as small as possible.<br /><br />This is really just a restatement of &quot;minimize untestable code&quot;, but I take issue with that phrasing, because it&#39;s defeatist (especially in a nice, dynamic language like Python). <em>All</em> code is testable: this strategy should be a temporary measure as you work towards developing <em>good</em> test support for your &quot;untestable&quot; interfaces and thinning out unnecessary coupling.  I think that it may be worthwhile to do some planning and architecture around your test development as well as your main body of code.</div>
</div>
<div class='comment'>
<div class='author'>glyph<span class='comment-date'> on 2010-09-08 20:57</span></div>
<div class='content'>
This seems like it could use a little expanding; it seems to be written for an audience that mostly understands what you&#39;re talking about already, and will just evoke familiar pangs rather than really educate.  <em>Why</em> is code-and-cover dull?  You write the same tests and code either way, right?  Why is it harder to get full coverage?  You just write your tests and then run your coverage tool, of course.<br /><br />I think that there are a lot of folks out there who do code-and-cover but don&#39;t really know why it&#39;s not as good as TDD.  A more expansive post would benefit them quite a bit.<br /><br />(Of course, <em>I</em> know the answers, as do many of your readers, but I&#39;m too lazy to write a good post in response, so I&#39;m hoping you&#39;ll do it for me ;-)).<br /><br />For my part, I do sometimes have trouble getting tests first, mostly in not-fully-covered code that has a big pile of existing dependencies that don&#39;t have test mocks, and building out even the most trivial test infrastructure would take substantially longer than just fixing a simple bug.  However, when I do get around to fixing it &quot;for real&quot;, I try to avoid the code-and-cover mistake of writing a test that passes first: I cut the whole implementation into another file, write a test, and get it to fail first, then start re-importing the smallest bits I need to get my test passing.  Once I&#39;m in the TDD groove again, I will quite often spot uncovered or buggy chunks of functionality and get them fixed right.<br /><br />The few times I have tried to just write tests for existing code without modifying it so that it will fail, it&#39;s been a complete mess.</div>
</div>
<div class='comment'>
<div class='author'>Julian<span class='comment-date'> on 2010-09-08 15:52</span></div>
<div class='content'>
The big exception to the rule for me is a prototype, which then turns into something useful.  There&#39;s no way I am going to write tests up front for a prototype.</div>
</div>
<div class='comment'>
<div class='author'>doxxxicle<span class='comment-date'> on 2010-09-07 15:27</span></div>
<div class='content'>
I tend to be a &quot;code &amp; cover&quot; type, mostly because the environments and systems I write for are hard to simulate in a test and I often am not sure what I need to do beforehand or how to do it &#8211; i.e. prototyping work.<br /><br />Not very good excuses, I know.</div>
</div>
<div class='comment'>
<div class='author'>absoludity<span class='comment-date'> on 2010-09-07 14:53</span></div>
<div class='content'>
The point that I enjoy the most about writing tests first is that it breaks the task down into a lot of mini-successes: write test, run code to show failure, add functionality, run test, success! For me it makes it a bit more like a game where you&#39;re always trying to reach the next level which is just out of reach.<br /><br />Without writing tests first, it&#39;s more like a long wait until a (potentially) big success, followed by many small failure moments as you start finding bugs.<br /><br />But I agree with Martin&#8230; when I&#39;m unsure about which way to go, <i>sometimes</i> a tracer bullet helps me see how I can test.</div>
</div>
<div class='comment'>
<div class='author'>Martin<span class='comment-date'> on 2010-09-07 12:46</span></div>
<div class='content'>
I&#39;ve been flip-flopping a lot on this. I probably do more TDD than not, but there are still scenarios where I just can&#39;t start off with tests. Usually, it&#39;s because I either don&#39;t understand the problem well enough yet, or because the testing infrastructure work needed is pretty big, and I can&#39;t bring myself to spending so much time upfront on it.</div>
</div>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/2010/09/unittest-api-part-4.html">unittest API, part 4</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-09-06T00:00:00+01:00" pubdate data-updated="true">2010-09-06 Monday</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
As I said at the very beginning, unittest has an API with lots of interfaces. You can read about the interfaces for test frameworks in <a href="http://code.mumak.net/2010/07/unittest-api-part-1.html">part 1</a>, <a href="http://code.mumak.net/2010/07/unittest-api-part-2.html">part 2</a> and <a href="http://code.mumak.net/2010/08/unittest-part-3.html">part 3</a> of this series. This post is about the interface for test authors.<br /><br />If the other posts are fresh in your mind, it&#8217;s important to remember that this post is focused on the standard implementation of <code>TestCase</code>. After all, it&#8217;s that implementation which creates the interface for test authors. There are other implementations (e.g. <code>FunctionTestCase</code> and <code>DocTestCase</code>) which provide completely different interfaces for test authors, and one could write one&#8217;s own implementation that provided something else entirely.<br /><div><br /></div><div><b>Subclassing <code>TestCase</code></b></div><div><br /></div><div>Almost all of the time that you want to write tests, you subclass unittest.TestCase. It&#8217;s not the only way to write unit tests with unittest, but it&#8217;s rather handy, particularly since the default test loader looks for subclasses of <code>TestCase</code>.<br /><br />This is going to be much easier for all of us if I work from an example.</div><br /><pre>class SomeTests(TestCase):<br />  def setUp(self):<br />    print "setUp"<br />  def tearDown(self):<br />    print "tearDown"<br />  def test_a(self):<br />    print "a"<br />  def test_b(self):<br />    print "b"<br /></pre><br /><div>The test loader will make something that looks like <code>unittest.TestSuite([SomeTests("test_a"), SomeTests("test_b")])</code>. That is, it constructs an instance of <code>SomeTests</code> for each method beginning with &#8220;test&#8221;.<br /><br />The tests will only be run when <code>TestCase.run(result)</code> is called. The tests do not get access to the result object, instead the run() method mediates between the tests and the result.<br /><br />The default <code>TestCase.run(result)</code> method will run <code>setUp()</code>, then the test method given in the constructor (e.g. <code>test_a</code>), then <code>tearDown()</code>.<br /><br />If <code>setUp()</code> raises any exception, <code>tearDown()</code> will not be run. The result object will have <code>addError</code> called on it with the test and the error.<br /><br />If the test method raises an exception, one of two things can happen. If the exception is an instance of <code>self.failureException</code>, then <code>result.addFailure(test, exc_info)</code> is called, where test is the <code>TestCase</code> instance and <code>exc_info</code> is the <code>sys.exc_info()</code> tuple. Otherwise, <code>result.addError(test, exc_info)</code> is called. In either case, <code>tearDown()</code> is then run.<br /><br />If <code>tearDown()</code> raises an exception, <code>result.addError(test, exc_info)</code> is called.<br /><br />There are lots of built-in assertion methods on <code>unittest.TestCase</code>. These all raise <code>self.failureException</code> if their assertion fails. These are part of the interface for test authors, but they are already very well documented. Just note that if you write your own, remember to raise <code>self.failureException</code>, or better yet call <code>self.fail()</code>, rather than raising <code>AssertionError</code> or something crazy like that.<br /><br />That&#8217;s pretty much it.<br /><br />Of course, you could write your own object that implemented <b><code>ITest</code></b> and <b><code>ITestCase</code></b>, and use your own test loader, and then you don&#8217;t have to care about anything in this post. But don&#8217;t do that. Better to subclass <code>unittest.TestCase</code>.<br /><br />As always, feedback welcome.</div></div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/2010/08/unittest-part-3.html">unittest, part 3</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-08-14T00:00:00+01:00" pubdate data-updated="true">2010-08-14 Saturday</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
So far, we&#8217;ve talked about <code>TestSuite</code>s, <code>TestCase</code>s and <code>TestResult</code>s. We&#8217;ve seen how these objects interact with each other &nbsp;and how they can generally be thought about as having more than one interface. <code>TestResult</code> has an interface for the <code>TestCase</code> and an interface used for querying the results, <code>TestCase</code> has an interface for test runners and an interface for test authors, and so forth.<br /><br />Now we need to give some time to the bits that glue everything together: the test runner and the test loader.<br /><br /><b><code>TestRunner</code></b><br /><br />You will not find a class in unittest.py called <code>TestRunner</code>. A test runner is simply something that takes user input about a test run – what tests to run, what manner to run them in, how to display the results – and does it.<br /><br />Essentially, it does something like this:<pre>  test = TestLoader().loadTests(user_specified_test_string)<br />  result = makeTestResult(options_specified_by_user)<br />  result.startTestRun()<br />  try:<br />    test.run(result)<br />  finally:<br />    result.stopTestRun()<br /></pre><br />And that&#8217;s it.<br /><br />You see that the test runner is responsible for instantiating the test loader and the test result. It&#8217;s perhaps excusable for a test runner to be tightly bound to particular implementations of test loader and test result. Certainly, before <code>TestResult</code> grew <code>startTestRun</code> and <code>stopTestRun</code> it was inevitable: since the test runner was responsible for summarizing the results of a test run, overall responsibility for displaying the results was split between the runner and the result.<br /><br />Nowadays, the tight coupling can be limited. If your test runner has an option to display stack traces as it gets them, then that&#8217;s pretty much going to force you to use a particular result. However, you can still write your code internally such that someone could pass in a different result that still works, even though it doesn&#8217;t do exactly what the user asked for.<br /><br /><b><code>TestLoader</code></b><br /><br />From the point of view of interfaces and compatibility, this is a pretty boring class, and that&#8217;s a good thing. The test loader&#8217;s job is to find tests based on some user input and construct a single <code>ITest</code> object for them.<br /><br />When it does more than this, one runs the risk of having the behaviour of a test suite depend too much on the runner itself. The ideal is to have the test suite run in any runner: trial, nose, unittest2, py.test, whatever.<br /><br />Some <code>TestLoader</code>s provide hooks so that users with complicated test suites can customize the way their tests are loaded. Whenever the Trial <code>TestLoader</code> sees a <code>test_suite()</code> function in a module, it lets that function take charge of the loading.<br /><br />The standard library in 2.7 has a new hook, inspired by an innovation in bzrlib, but slightly different. <code>load_tests(loader, standard_tests, pattern)</code> is given the loader used by the test runner, the tests that the loader would have loaded, and if appropriate, a glob used for matching test module files. The advantage of this hook is that it reduces the danger of customizations made to the loader, since the test suite has access to the same loader. It also makes custom loading easier by giving the standard tests as a starting point. bzrlib uses this to run the same set of tests against many implementations.<br /><br />I <i>think </i>that&#8217;s all I have to say about these two, which means that&#8217;s pretty much all I have to say about unittest&#8217;s API for test frameworks. Still one more post to go though: interfaces for test authors.<br /><br />Let me know if I&#8217;ve missed anything, if anything here surprises you or contradicts something I said in the past or if things are unclear. The comments on the previous two posts have really helped!</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/2010/07/unittest-api-part-2.html">unittest API, part 2</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-07-30T00:00:00+01:00" pubdate data-updated="true">2010-07-30 Friday</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
In <a href="http://code.mumak.net/2010/07/unittest-api-part-1.html">part 1</a> of this humble attempt to document the interfaces and contracts that unittest actually cares about, we talked about <code>TestSuite</code> and <code>TestCase</code>, how they both implement a common interface that&#8217;s used for running tests, <b><code>ITest</code></b> and how they each implement their own interfaces, <b><code>ITestSuite</code></b> and <b><code>ITestCase</code></b>.<br /><br />Now we&#8217;re moving on to a much more complicated object, <code>TestResult</code>, to see how we can pick apart the ways it interacts with the rest of the system.<br /><br /><b><code>TestResult</code></b><br /><br />A <code>TestResult</code> object is all about dealing with the results of tests, as you might expect. However, it doesn&#8217;t generally represent a <i>single</i> test result. You could say it represents the results of a number of tests, but I don&#8217;t think that&#8217;s terribly helpful.<br /><br />Better to think of a <code>TestResult</code> object as an event handler. A <code>TestResult</code> object receives events from a test run and then does something with them.<br /><br />Just as <code>TestCase</code> has a two-faced nature, presenting one interface to the testing framework and another to test authors, so to <code>TestResult</code> can be thought of has having many interfaces:<br /><ol><li>Its interface to a <code>TestCase</code>. This can be thought of as the <i>test event handling </i>interface</li><li>A <i>result querying</i>&nbsp;interface, normally used by a test runner</li><li>An interface for events that come from the test runner, the <i>runner event handling</i> interface.</li><li>An <i>execution control</i> interface.</li></ol>Note that the <i>result querying</i>&nbsp;interface and the <i>runner event handling</i>&nbsp;interface together make up the interface between the <code>TestResult</code> and test runner.<br /><br />Let&#8217;s start with the <i>test event handling</i> interface. The methods below are the interface between <code>TestCase.run()</code> and <code>TestResult</code>. (I guess <code>TestCase.debug</code> too, but no one cares about it).<br /><dl><dt><code>startTest(test)</code></dt><dd>Called when <code>test</code> commences running. Although not enforced, it&#8217;s impolite to provide any results for <code>test</code> before calling this.</dd><dt><code>stopTest(test)</code></dt><dd>Called when <code>test</code> is completely finished. Although not enforced, it&#8217;s impolite to provide any more results for <code>test</code> after calling this, unless you call <code>startTest(test)</code> again first.</dd><dt><code>addSuccess(test)</code></dt><dd>Called when <code>test</code> has been shown to be successful. The default implementation does nothing.</dd><dt><code>addError(test, err)</code></dt><dd>Called when <code>test</code> raises an unexpected error. <code>err</code> is a tuple such as you might get from <code>sys.exc_info()</code>. Calling this method for the first time must change the result of <code>wasSuccessful()</code>.</dd><dt><code>addFailure(test, err)</code></dt><dd>Called when <code>test</code> has failed one of its assertions. <code>err</code> is a tuple such as you might get from <code>sys.exc_info()</code>.</dd></dl>The above interface is tightly coupled to the implementation of <code>TestCase.run()</code>. In particular, if you wish to add more kinds of results to your testing framework (&#8220;skip&#8221; results are a fairly common addition), then you must change both <code>TestCase.run()</code> and the <code>TestResult</code> interface.<br /><br />If you do something like that, I recommend making sure that your modified <code>TestCase</code> can handle <code>TestResult</code> objects that do not provide the extensions to the interface that you need. One common way of doing this is to have the <code>TestCase</code> fall back to the primitive result types, e.g. &#8220;skip&#8221; might become &#8220;success&#8221; for a <code>TestResult</code> that doesn&#8217;t know what skipping means.<br /><br />Importantly, the interface between <code>TestCase</code> and <code>TestResult</code> has been fattened in Python 2.7.<br /><dl><dt><code>addSkip(test, reason)</code></dt><dd>Called when <code>test</code> is skipped. <code>reason</code> is a string explaining why the test was skipped.</dd><dt><code>addExpectedFailure(test, err)</code></dt><dd>Called when <code>test</code> failed in a way that was expected. <code>err</code> is a tuple such as the one returned by <code>sys.exc_info()</code>.</dd><dt><code>addUnexpectedSuccess(test)</code></dt><dd>Called when <code>test</code> was expected to fail, but didn&#8217;t.</dd></dl>The following interface is a way of learning about test results after they have happened, the <i>result querying</i> interface, and is part of the contract between the test runner and the TestResult.<br /><dl><dt><code>wasSuccessful()</code></dt><dd>If there have been no errors and no failures, return <code>True</code>. Return <code>False</code> otherwise.</dd><dt><code>testsRun</code></dt><dd>An integer that is the number of tests that have been run.</dd><dt><code>errors</code></dt><dd>A list of tuples of <code>(test, error_message)</code> for all of the tests with unexpected errors, where <code>test</code> is an <code>ITestCase</code> and <code>error_message</code> is a string suitable for display to humans, generally containing a traceback.</dd><dt><code>failures</code></dt><dd>A list of tuples of <code>(test, error_message)</code> for all of the failing tests, where <code>test</code> is an <code>ITestCase</code> and <code>error_message</code> is a string suitable for display to humans, generally containing a traceback.</dd> </dl>And of course, Python 2.7 fattens this interface again to have the following:<br /><dl><dt><code>skipped</code></dt><dd>A list of tuples of <code>(test, reason)</code> for all of the skipped tests, where <code>test</code> is an <code>ITestCase</code> and <code>reason</code> is a string suitable for display to humans, generally containing a traceback.</dd><dt><code>expectedFailures</code></dt><dd>A list of tuples of <code>(test, error_message)</code> for all of the tests that were expected to fail and failed in the manner they were expected to, where <code>test</code> is an <code>ITestCase</code> and <code>error_message</code> is a string suitable for display to humans, generally containing a traceback.</dd><dt><code>unexpectedSuccesses</code></dt><dd>A list of all of the tests that unexpectedly succeeded. Members of the list are <code>ITestCase</code>s.</dd></dl>In Python 2.7,&nbsp;<code>TestResult</code>&nbsp;also extended its interface to the test runner beyond simple result querying and into allowing the test runner itself to send two very important events to the <code>TestResult</code>, behold the <i>runner event handling</i> interface:<br /><dl><dt><code>startTestRun()</code></dt><dd><div style="margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px;">Called before any tests have been run. It is impolite to provide any test results before calling this.</div></dd><dt><code>stopTestRun()</code></dt><dd><div style="margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px;">Called after all the tests have finished running. It is impolite to provide any test results after calling this. A&nbsp;<code>TestResult</code>&nbsp;object is generally not expected to handle any events at all after this method has been called.</div></dd></dl>Some test runners rely on <code>TestResult</code>s to use those events to display the results to the user. These runners frequently do not use the result querying part of the interface.<br /><br />There is one more interface that <code>TestResult</code> implements: the <i>execution control</i> interface:<br /><dl><dt><code>stop()</code></dt><dd>Signal that the execution of further tests should stop now. Sets <code>shouldStop</code> to <code>True</code>.</dd><dt><code>shouldStop</code></dt><dd>If <code>True</code>, then test execution should stop. <code>TestSuite.run()</code> should monitor this value and stop execution if ever it is <code>True</code>.</dd><dt></dt></dl>This interface is mostly used as a way of handling <code>KeyboardInterrupt</code>s cleanly.<br /><br /><b>Summary</b><br /><br />If you want your <code>TestResult</code> object to work with standard Python <code>TestCase</code> objects, or any <code>TestCase</code> objects that try to stick close to the standard, then you must provide the <i>test&nbsp;event handling</i> interface described above. If you are writing your own test framework or test runner, you care about this, because you want to run everyone&#8217;s unit tests.<br /><br />If you want your <code>TestResult</code> object to work with the standard Python test runner before Python 2.7, then you must provide the <i>result querying</i> interface. If you are using the standard Python test runner, you care about this. For Trial or testtools, you must provide the <i>runner event handling</i>&nbsp;interface.&nbsp;For anything else, I&#8217;m afraid you are on your own.<br /><br />Always provide the <i>execution control</i> interface.<br /><br /><b>Comments</b><br /><br />In this documentation, I&#8217;ve been trying to describe the various interfaces without inserting too much of my own opinion about their design. However, I think some commentary might actually help to make things easier to understand.<br /><br />By providing a querying interface for <code>TestResult</code> to be used by a test runner, the original designers of unittest practically insisted that responsibility for displaying the results of a test run be split between two different classes. The <code>TestResult</code> takes care of displaying incremental feedback from the running tests and the test runner takes care of displaying the summary. You can see evidence of this design in Python 2.6&#8217;s unittest.py, where there&#8217;s a hidden <code>_TextTestResult</code> subclass which has extra methods that are called only by a special <code>TextTestRunner</code>.<br /><br />The addition of <code>startTestRun()</code> and <code>stopTestRun()</code> mean that now a <code>TestResult</code> object can be fully in charge of displaying its results. As such, providing a query interface and exposing details like the list of test failures somewhat vestigial. <br /><br />I&#8217;m less happy with this post than the previous one. As such your critique is even more welcome.<br /><br />Still to come: the interface for test authors and just what is a test runner anyway?<br /><br /><b>Update:</b> Remove ambiguity in <code>expectedFailures</code> description (see comments). Thanks Aaron.</div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>Aaron<span class='comment-date'> on 2010-07-30 19:36</span></div>
<div class='content'>
In your description of expectedFailures:<br /><i>A list of tuples of (test, error_message) for all of the tests that were expected to fail, where test is an ITestCase and error_message is a string suitable for display to humans, generally containing a traceback.</i><br /><br />There is some ambiguity.  I think you mean that it is a list of tests that failed in the expected way, rather that tests that were expected to fail (whether or not they actually did fail that way).</div>
</div>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/2010/07/unittest-api-part-1.html">unittest API, part 1</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-07-29T00:00:00+01:00" pubdate data-updated="true">2010-07-29 Thursday</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
It&#8217;s a little known fact, but unittest actually has an API.<br /><br />This isn&#8217;t the API that you deal with when you write tests, but rather an API that unittest itself uses when running tests. You could think of it as two interfaces: one for test frameworks and one for test authors. Both APIs are real, but both are poorly documented and often misunderstood or abused.<br /><br /><b><code>TestCase</code></b><br /><br />An instance of <code>TestCase</code> represents a single test. What you think of as a single test is up to you, but most of the time it&#8217;s a unit test.<br /><br />A <code>TestCase</code> object <i>must</i> provide the following methods.<br /><br />This first list of methods can be thought of as a single interface, which these blog posts will call <b><code>ITest</code></b> given the lack of any better name.<br /><dl><dt><code>countTestCases()</code></dt><dd>A method that returns the number of test cases this represents. It should always return 1.  </dd><dt><code>run(result=None)</code></dt><dd>Calling this method actually runs the test. <code>result</code> is a <code>TestResult</code> object. <code>run</code> must call <code>result.startTest(self)</code> when it commences running the test and <code>result.stopTest(self)</code> when it is finished. Between these calls it must call a method on <code>result</code> to signal the result of the test. <code>run</code> must never raise an exception, and its return value is ignored. If <code>result</code> is not provided, the <code>TestCase</code> is obliged to make one.  </dd><dt><code>__call__(result)</code></dt><dd>Identical to <code>run(result)</code>, provided for backwards compatibility.  </dd><dt><code>debug()</code></dt><dd>Calling this method runs the test without collecting its results. It may raise exceptions. This method is rarely called by test frameworks.</dd></dl><br />The following methods are specific to individual test case objects. We call this interface <b><code>ITestCase</code></b>.<br /><br /><dl><dt><code>id()</code></dt><dd>Should return a string that uniquely identifies the test. For Python tests, the fully-qualified Python name works well. The uniqueness of the id is not enforced.  </dd><dt><code>shortDescription()</code></dt><dd>Should return a string that describes the test. Many test frameworks use this value to display test results.  </dd><dt><code>__str__</code></dt><dd>Should return a string that describes the test. Frequently the same as either <code>shortDescription()</code> or <code>id()</code>. Many test frameworks use this value to display test results.</dd></dl>There is also a second interface, one that matters to code that subclasses <code>TestCase</code>. We&#8217;ll deal with that in a later post.<br /><br /><b><code>TestSuite</code></b><br /><br />A <code>TestSuite</code> represents nothing more or less than a bunch of tests.<br /><br />A <code>TestSuite</code> must provide the <code>ITest</code> interface described above, with the differences that you would expect from something that represents many tests: <code>countTestCases</code> returns the number of tests in the suite; <code>run</code> runs many tests and thus calls <code>result.startTest</code> and kin many times over; <code>debug</code> is the same and can explode anywhere.<br /><br />One difference is that <code>TestSuite.run</code> must stop running tests as soon as it detects that <code>result.shouldStop</code> is true.<br /><br />In addition, <code>TestSuite</code> implements the following interface, which I&#8217;m giving the completely arbitrary non-existent name of <code><b>ITestSuite</b></code>.<br /><dl><dt><code>addTest(test)</code></dt><dd>Takes an <code>ITest</code> and adds it to the suite.  </dd><dt><code>addTests(tests)</code></dt><dd>Takes an iterable of <code>ITest</code>s and adds them to the suite. Normally equivalent to <code>[suite.addTest(test) for test in tests]</code>.  </dd><dt><code>__iter__</code></dt><dd>All test suites must be iterable. Iterating over a test suite yields <code>ITest</code>s. These may differ from the <code>ITest</code>s provided to <code>addTest</code> and <code>addTests</code>.</dd> </dl>In later posts, I hope to document <code>TestResult</code>, the subclassing interface of <code>TestCase</code> and tell you exactly what I think about test loaders, test runners and the like.<br /><br />I&#8217;m blogging this partly because I don&#8217;t know where else to write this up, but mostly because I need your help to make sure that I&#8217;m being clear and correct. Please comment with questions and corrections, and let me know if you find this at all helpful.</div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>jml<span class='comment-date'> on 2010-08-02 12:13</span></div>
<div class='content'>
Aaron, an <i>instance</i> of TestCase is a single test.<br /><br />When you have many test_ methods on a TestCase, what actually happens is that one TestCase object gets constructed for each test method.<br /><br />Say you&#39;ve got:<br /><br />class TestFoo(TestCase):<br />  def test_a(self):<br />    pass<br />  def test_b(self):<br />    pass<br /><br />(please forgive the lack of indentation.)<br /><br />Then the default test loader will construct something like:<br />[TestFoo(&quot;test_a&quot;), TestFoo(&quot;test_b&quot;)]<br /><br />Thanks for asking the question. It&#39;s a common point of confusion. Indeed, it tripped me up the first year or so I was writing Trial.</div>
</div>
<div class='comment'>
<div class='author'>Aaron<span class='comment-date'> on 2010-07-30 19:29</span></div>
<div class='content'>
I don&#39;t understand how a TestCase can be a single test when the test suites I use all have multiple test cases per TestCase.</div>
</div>
<div class='comment'>
<div class='author'>jml<span class='comment-date'> on 2010-07-30 16:39</span></div>
<div class='content'>
Thanks for the comments all. I&#39;m glad you like it.<br /><br />Michael, once I&#39;m finished with the series and have a chance to get some more feedback – particularly from other framework authors – I&#39;ll try to turn these into patches. (And also try to get over the fact that I won&#39;t be able to use zope.interface to do so).<br /><br />Your plugin proposal is up there on my list of things to respond to, but I likely won&#39;t get a chance until the weekend.</div>
</div>
<div class='comment'>
<div class='author'>Michael Foord<span class='comment-date'> on 2010-07-30 16:20</span></div>
<div class='content'>
Great stuff Jonathan. If you want to formulate these as patches to the unittest docs then please feel free. :-)<br /><br />Would be interested in your feedback on my unittest plugin proposal too.</div>
</div>
<div class='comment'>
<div class='author'>jam<span class='comment-date'> on 2010-07-30 15:51</span></div>
<div class='content'>
I think it is quite useful.<br />We&#39;ve certainly had our share of unittest issues in bzr, so it is nice to have a fairly easy-to-read explanation of how it is at least <i>supposed</i> to work.</div>
</div>
<div class='comment'>
<div class='author'>Kevin H<span class='comment-date'> on 2010-07-30 04:23</span></div>
<div class='content'>
Heck yeah, it&#39;s useful!<br /><br />Please keep it up!</div>
</div>
</div>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/8/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/6/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/2013/04/deliberately-being-naughty.html">Deliberately being naughty</a>
      </li>
    
      <li class="post">
        <a href="/2013/02/testtools-moved-to-github.html">testtools moved to Github</a>
      </li>
    
      <li class="post">
        <a href="/2013/02/are-single-variable-names-evil.html">Are single letter variable names evil?</a>
      </li>
    
      <li class="post">
        <a href="/2012/12/getting-set-up-with-twisted-development.html">Getting set up with Twisted development</a>
      </li>
    
      <li class="post">
        <a href="/2012/11/whats-wrong-with-orms.html">What&#8217;s wrong with ORMs</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/jml">@jml</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'jml',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>



<section class="googleplus googleplus-hidden">
  <h1>
    <a href="https://plus.google.com/jonathan.lange?rel=author">
      <img src="http://www.google.com/images/icons/ui/gprofile_button-32.png" width="32" height="32">
      Google+
    </a>
  </h1>
</section>



  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Jonathan Lange -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  





  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
